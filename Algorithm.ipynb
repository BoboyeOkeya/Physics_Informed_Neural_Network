{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a41c8fb",
   "metadata": {},
   "source": [
    "## Algorithm A1: The PINN algorithm\n",
    "1. **Import** the neccessary libraries\n",
    "2. Load the training and test dataset: acquired from simulation\n",
    "3. Create two neural networks ($N_1$ and $N_2$):\n",
    "    - Define: input and output dimensions, number of hidden layers, and neurons.\n",
    "    - Add `J`, `B`, and `K_t` as constrained weights or trainable parameters to $N_1$.\n",
    "    - Add `R`, `L`, and `K_b` as constrained weights or trainable parameters to $N_2$.\n",
    "4. Initialize the weights and biases of $N_1$, $N_2$.\n",
    "5. Tune the hyperparameters\n",
    "    - Define the hyperparameter search space for both $N_1$ and $N_2$\n",
    "    - Generate all the hyperparameter combination\n",
    "    - **For** each combination/set of hyperparameter:\n",
    "        - Initialize and build the model with the present set of hyperparameters\n",
    "        - Choose and configure the optimizer\n",
    "        - Train $N_1$ and $N_2$:\n",
    "            - for `g` ‚Üê 1 to number of epochs (epoch could be a hyperparameter too):\n",
    "                - Get the predicted training dataset $\\hat{\\omega} = N_1(t,v,\\tau_L)$ and $\\hat{I} = N_2(t,v,\\tau_L)$\n",
    "                - Compute the derivative of the two networks: $\\frac{d\\hat{\\omega}}{dt}$ and $\\frac{d\\hat{I}}{dt}$.\n",
    "                - Compute the system residuals (physics losses with the losses due to prediction):\n",
    "                    - $L_1 = \\frac{1}{N}\\sum^{N-1}_i\\left( J\\frac{\\hat{\\omega}(i)}{dt} + B\\hat{\\omega}(i) + \\tau_L(i) - K_t \\hat{I}(i)\\right)^2$\n",
    "                    - $L_2 = \\frac{1}{N}\\sum^{N-1}_i\\left( L\\frac{d\\hat{I}(i)}{dt} + R\\hat{I}(i) - v(i) +  K_b \\hat{\\omega}(i)\\right)^2$\n",
    "                    - $L_3 = \\sum^N_i\\left(\\hat{\\omega}(i)- \\omega(i)\\right)^2$\n",
    "                    - $L_4 = \\sum^N_i\\left(\\hat{I}(i)- I(i)\\right)^2$\n",
    "                    - $L_{T1} = L_1 + L_3$, $L_{T2} = L_2 + L_4$\n",
    "                - Compute the losses' gradient $L_{T1}$ and $L_{T2}$ with respect to all the network parameters\n",
    "                - Update the network parameters(weights, biases and unknown parameters) of $N_1$ and $N_2$\n",
    "                - Sum the losses of the two networks, $L_{T} = L_{T1} + L_{T2}$\n",
    "            - end for loop\n",
    "        -If the total loss $L_{T}$ is the minimum loss:\n",
    "            - store the loss $L_{T}$ and the hyperparameter set\n",
    "    -end for loop and return the hyperparameter combination that gives the lowest loss $L_{T}$\n",
    "6. Train networks $N_1$ and $N_2$ using the optimal hyperparameter set.\n",
    "    - Follow the training procedures under step 5\n",
    "7. Test the trained network with the test data and visualize the result\n",
    "8. Save the two models $N_1$ and $N_2$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
